<!DOCTYPE html>
<html>
<head>
	<title>Results</title>
    <link rel="stylesheet" type="text/css" href="../static/css/styles.css">
</head>
<body>
	<header>
		<div class="container">
			<h2>Spam Detector For SMS Messages</h2>
		  <h3>A Machine Learning App That Explains It All</h3>
		</div>
	</header>
	<div class="results">
		{% if prediction == 1%}
			<h2 style="color:#e0392d;">That was not a nice message...</h2>
		{% elif prediction == 0%}
			<h2 style="color:#3d7aba;">Thank you, that <i>was</i> a nice message.</h2>
		{% endif %}
	</div>
	<p>
		<h3>How did the machine learning algorithm arrive at this prediction from your text message?</h3>
		<br>
		At a high level, these are the main steps in this app:
		<br><br>
		<center><img src="../static/img/Explanation1.PNG" alt="Explanation 1" width=95%></center>
		<p style="font-size:10px" align="center">
			Interior of a classroom, students bent at study, Yallourn, 1947.
			<br>
 			Photo by <a href="https://unsplash.com/@museumsvictoria">Museums Victoria</a>
			in <a href="https://unsplash.com/">Unsplash</a>.
		</p>
		<br>
		<h2 style="color:#3c90b5; text-align:center">Processing The Text</h2>
		Most of the time is spent processing the text as this numeric array that the ML model can understand.
		Prediction happens quickly after that. Processing takes several steps:
		<ul>
			<li>Creating Bag of Words (BoW)</li>
			<li>Tranforming the BoW into a Document-Term Frequency Matrix (DTM)</li>
			<li>Converting the DTM into a Document-Term TF-IDF Matrix</li>
			<li>Reducing Dimensions via Singular Value Decomposition</li>
			<li>Computing Mean Spam Cosine Similarities</li>
		</ul>
		<br>
		As a motivating example, let's follow this spam text taken from our collection (with some modifications):
		<p style="font-family:monospace; text-align:center">
			For a chance to win a å£250 cash TXT: ACTION to 80608. U won't be sorry -visits @www.movietrivia.tv @8pm PDT!
		</p>
		<br>
		<h3>Creating a Bag of Words (BoW)</h3>
		<br>
		<b>Parsing:</b> we cleanup the text, that is: lower case, remove  punctuation, replace URLs and numbers, and so forth.
		<br><br>
		<button onclick="ShowDeets1()">See Details</button>
		<br>
		<div id="Deets1">
		<br>
		These are some of the steps performed, for a deeper look into all the preprocessing see the source code (link below).
		<br><br>
			<table class="table table-striped">
				 <thead>
			 		 <tr>
						 	<th>Step</th>
							<th>Result</th>
					</tr>
				 </thead>
				 <tbody>
						 	<tr>
								<td>Expand Contractions</td>
								<td>For a chance to win a å£250 cash TXT: ACTION to 80608. U will be sorry -visits @www.movietrivia.tv @8pm PDT!</td>
							</tr>
							<tr>
								<td>Lower Case</td>
								<td>for a chance to win a å£250 cash txt: action to 80608. u will not be sorry -visits @www.movietrivia.tv @8pm pdt!</td>
							</tr>
							<tr>
								<td>Replace URLs</td>
								<td>for a chance to win a å£250 cash txt: action to 80608. u will not be sorry -visits  URL  @8pm pdt!</td>
							</tr>
							<tr>
								<td>Replace Numbers</td>
								<td>for a chance to win a å£ NUM  cash txt: action to  NUM . u will not be sorry -visits  URL  @ NUM pm pdt!</td>
							</tr>
							<tr>
								<td>Remove Punctuation</td>
								<td>for a chance to win a å NUM cash txt action to NUM u will not be sorry visits URL NUM pm pdt</td>
							</tr>
							<tr>
								<td>Replace Emojis</td>
								<td>for a chance to win a  EMOJI  NUM cash txt action to NUM u will not be sorry visits URL NUM pm pdt</td>
							</tr>
				 </tbody>
			</table>
		</div>
		<br>
		<b>Tokenizing:</b> we split the text into chunks (tokens), remove common words, lemmatize, and group into ngrams.
		<br>
		<br>
		<button onclick="ShowDeets2()">See Details</button>
		<div id="Deets2">
		<br>
		Very common words ("stop words") are removed as they provide little signal, and words are
		<a href="https://en.wikipedia.org/wiki/Lemmatisation">lemmatized</a> so as to standardize some of the variety and try to capture more signal.
		We then form two and three-long sequences of tokens (bigrams and trigrams) to capture some of the order in the text.
		These steps attempt to capture some of the meaning behind a message. There are many other ways to do this, for example, with deep learning architectures
		and <a href="https://en.wikipedia.org/wiki/Long_short-term_memory">LSTM (Long-Short-Term-Memory)</a> cells I could've capture more long-term connections
		between tokens in a text, not just consecutive chunks.
		<br><br>
		<table class="table table-striped">
			 <thead>
		 		 <tr>
					 	<th>Step</th>
						<th>Result</th>
				</tr>
			 </thead>
			 <body>
			 <tr>
				 <td>Tokenize</td>
				 <td>'for' 'a' 'chance' 'to' 'win' 'a' 'EMOJI' 'NUM' 'cash' 'txt' 'action' 'to' 'NUM' 'u' 'will' 'not' 'be' 'sorry' 'visits' 'URL' 'NUM' 'pm' 'pdt'</td>
			 </tr>
			 <tr>
				 <td>Remove Stop Words</td>
				 <td>'chance' 'win' 'EMOJI' 'NUM' 'cash' 'txt' 'action' 'NUM' 'u' 'not' 'sorry' 'visits' 'URL' 'NUM' 'pm' 'pdt'</td>
				</tr>
				<tr>
 				 <td>Lemmatize</td>
 				 <td>'chance' 'win' 'EMOJI' 'NUM' 'cash' 'txt' 'action' 'NUM' 'u' 'not' 'sorry' 'visit' 'URL' 'NUM' 'pm' 'pdt'</td>
 				</tr>
				<tr>
 				 <td>Add Ngrams</td>
 				 <td>'chance' 'win' 'EMOJI' 'NUM' 'cash' ...'for_a' 'a_chance' 'chance_to' 'to_win' 'win_a' ... 'visits_URL_NUM' 'URL_NUM_pm' 'NUM_pm_pdt'</td>
 				</tr>
		 	</tbody>
	 	</table>
		</div>
		<br>
		<br>
 	 	<b>Counting:</b> finally, we count repeated tokens (ngrams), creating a so-called 'Bag-of-Words' representation.
											Here are top and bottom rows of this BoW expressed as a table:
		<br><br>
		<table class="table table-striped">
			 <thead>
		 		 <tr>
					 	<th>Ngram</th>
						<th>Count</th>
				</tr>
			 </thead>
		<body>
				<tr>
					<td>chance</td>
					<td>1</td>
				</tr>
				<tr>
					<td>to</td>
					<td>1</td>
				</tr>
				<tr>
					<td>win</td>
					<td>1</td>
				</tr>
				<tr>
					<td>EMOJI</td>
					<td>1</td>
				</tr>
				<tr>
					<td>NUM</td>
					<td>3</td>
				</tr>
				<tr>
					<td>cash</td>
					<td>1</td>
				</tr>
				<tr>
					<td>...</td>
					<td>...</td>
				</tr>
				<tr>
					<td>sorry_visits_URL</td>
					<td>1</td>
				</tr>
				<tr>
					<td>visits_URL_NUM</td>
					<td>1</td>
				</tr>
				<tr>
					<td>URL_NUM_pm</td>
					<td>1</td>
				</tr>
				<tr>
					<td>NUM_pm_pdt</td>
					<td>1</td>
				</tr>
			</body>
		</table>
		<br>
		<button onclick="ShowDeets3()">See Your Bag-of-Words</button>
		<br><br>
		<div id="Deets3">
		<table class="table table-striped">
			 <thead>
		 		 <tr>
					 	<th>Ngram</th>
						<th>Count</th>
				</tr>
			 </thead>
			 <tbody>
					{% for key, value in counter.items() %}
					 	<tr>
						 	<td>{{key}}</td>
							<td>{{value}}</td>
						</tr>
					{% endfor %}
			 </tbody>
		</table>
	</div>
		<br><br>
		<a href="https://github.com/BigBangData/SMS_SpamDetect/blob/74ca298ef7cffccca1350f852766b2401d7a4e91/custom/clean_preprocess.py#L203">Source Code</a>
	</p>
	<p>
		<br>
		<h3>Tranforming the BoW into a Document-Term Frequency Matrix (DTM)</h3>
		<br>
		We need to transform the Bag-of-Words into a numerical vector since ML models mostly take numbers as input.
		There are many ways to represent text as numbers but one of the most basic ways is a
		<a href="https://github.com/BigBangData/NaturalLanguageProcessing/blob/fuji/SMS_SpamDetect/Extra_Document_Term_Matrices.ipynb">Document-Term Frequency Matrix</a>
		where each row is a new document (new text in our case) in a corpus of documents (such as the SMS Collection the model was trained on) and each column is a term
		(a token), and cells contain the term frequency in a document (i.e. the number of times a word is used in a text).
		<br><br>
		<center><img src="../static/img/Explanation2.PNG" alt="Explanation 2" width=50%></center>
		<center><i>Simple DTM on a corpus of three documents</i></center>
		<br><br>
		So far processing a single text in this app is the same as the processing I applied when preparing many texts for the ML model.
		From now on, because we're using a single text with new words and I trained on a fixed corpus of texts and words, the steps differ.
		<br><br>
		For example, the <b>vocabulary of tokens</b> in the SMS Spam Collection is different than the vocabulary of tokens provided to this app. The latter is much smaller,
		yet it might contain new tokens. We need to <b>cast, or project</b> the new tokens into the same shape of the original DTM created during training: <b>same tokens,
		in the same order</b>.If we didn't do this, the ML model would not understand what to do - or rather, it'd just predict nonsense since it doesn't actually
		understand anything.
		<br><br>
		<center><img src="../static/img/Explanation3.PNG" alt="Explanation 3" width=50%></center>
		<center><i>Projecting new document into training DTM</i></center>
		<br><br>
		During training the original vocabulary size had ~40,000 unigram tokens, and would be much larger with bigrams and trigrams. After many tests I selected the most common
		2,000 tokens as the ideal size for my training DTM, balancing a trade-off between accuracy and speed. Below are the first 42 tokens (of 2,000) which were the most common
		in the training data, and their new counts.
		<br><br>
		<table class="table table-striped">
			 <thead>
				 <tr>
					 <th>Training Tokens -> </tg>
					 {% for token in vocabulary %}
						 {% if loop.last %}
						  <th> . . . . </th>
						 {% else %}
						 	<th>{{token}}</th>
						 {% endif %}
			 	 	 {% endfor %}
				 </tr>
			 </thead>
			 <tbody>
					 <tr>
						 <td>New Token Counts -> </td>
						 {% for count in bot %}
							 {% if loop.last %}
							   <td> . . . . </td>
							 {% else %}
						 	   <td>{{count}}</td>
							 {% endif %}
						 {% endfor %}
					 </tr>
			 </tbody>
		</table>
		<br><br>
		<a href="https://github.com/BigBangData/SMS_SpamDetect/blob/74ca298ef7cffccca1350f852766b2401d7a4e91/custom/deploy_models.py#L89">Deployment Code</a>,
		<a href="https://github.com/BigBangData/SMS_SpamDetect/blob/74ca298ef7cffccca1350f852766b2401d7a4e91/custom/clean_preprocess.py#L278">
			WordCounterToVectorTransformer Code</a>
	</p>
	</p>
	<p>
		<br>
		<h3>Converting the DTM into a Document-Term TF-IDF Matrix</h3>
		<br>
		For a single document, the vector of counts consists of mostly 0s since each text has a minuscule fraction of all tokens in all texts.
		This means the information signal in a given vector is very faint. To boost the signal we can leverage more of the information contained
		in the training data. So far we've counted the <b>TF</b> or <b>Term Frequency</b> of a token within a single document, but we can also
		count the <b>DF</b> or <b>Document Frequency</b> of documents within the entire corpus that have that token.
		<br><br>
		We can then pit the TF against the DF by using the inverse of the DF (for details see
		<a href="https://github.com/BigBangData/NaturalLanguageProcessing/blob/fuji/SMS_SpamDetect/Extra_Document_Term_Matrices.ipynb")>this notebook</a>)
		so as to balance out the importance of tokens in a document vs the corpus. Think of it like "removing stop words" from the corpus, if a
		term is very frequent in the corpus, it is not as informative to distinguish documents - TF*IDF boosts the importance of rare terms. (As a side
		note, the fact I'm doing this calculation after selecting the most common 2,000 terms might have defeated its purpose a bit.)
		<br><br>
		A neat property of the TF-IDF calculation is that the resulting values or scores are normalized between 0 and 1. Here's the result given our simple
		corpus. Notice how the TF-IDF scores capture better the meaning of the second document: since "love" and "you" are common in the corpus, their scores
		are a bit lower than the scores for "do" and "not".
		<br><br>
		<center><img src="../static/img/Explanation4.PNG" alt="Explanation 4" width=65%></center>
		<center><i>Conversion from counts to TF IDF scores</i></center>
		<br>
		<button onclick="ShowDeets4()">See Your DTM</button>
		<br><br>
		<div id="Deets4">
		A non-trivial aspect of this step in the processing pipeline is that it needs to remember the IDF values of the training data and apply a different
		calculation when processing the new text to come up with TF-IDF values. This happens because we cannot calculate IDF values using a corpus of one
		document, since there are no other messages. The table below shows the first 42 counts and TF-IDF scores  in term-document format for ease of comparison).
		<br><br>
		<table class="table table-striped">
			 <thead>
					 <tr>
						 	<th>Token</th>
							<th>Count</th>
							<th>Tfidf</th>
					</tr>
				</thead>
 			 <tbody>
					{% for token, count, tfidf in ziparrays %}
					{% if loop.last %}
					<tr>
						<td>...</td>
						<td>...</td>
						<td>...</td>
					</tr>
					{% else %}
				  		<tr>
						 		<td>{{token}}</td>
								<td>{{count}}</td>
								<td>{{tfidf}}</td>
							</tr>
					 {% endif %}
					 {% endfor %}
			 </tbody>
		</table>
		<br>
		<li>
			<b>Note:</b> If at first you don't see values, try using the tokens in the first column. Repeat the same token and notice what happens to the Tfidf value.
		</li>
	</div>
		<br>
		<a href="https://github.com/BigBangData/SMS_SpamDetect/blob/aae96efb6e5ba9875efa3a2ede8d70958d8e025f/custom/deploy_models.py#L89">Source Code</a>
		<br><br>
	</p>
	<p>
		<br>
		<h3>Reducing Dimensions via Singular Value Decomposition</h3>
		<br>
		While using a TF-IDF representation instead of simple counts boosts the training data's signal, we still have a 2,000-long sparse vector of mostly 0s.
		To solve this problem, a commonly used technique is to project this sparse matrix into what's called a <b>Latent Semantic</b> space using
		a mathematical technique called <b>Singular Value Decomposition  (SVD)</b>. This is a technique used for data compression and other applications. In
		simple terms, SVD reduces a large matrix with lots of columns into a small one with few columns, keeping as much of the original information as possible.
		In our case, we reduce 2,000 tokens into 800 "components" (columns) which capture most of the essence of the tokens into higher-level semantic concepts.
		<br><br>
		This is where explainability starts to fail and the so-called "black box" of machine learning starts. There's no learning yet, we're still just processing
		text, but an SVD projection is a mathematical procedure performed on numeric matrices. The way a human mind groups words into higher-levle concepts such
		as a phrase or a succint explanation of a concept, is conceivably very different than how SVD captures the variance of tokens into a single component
		that might best describe these tokens. In other words: I cannot tell you what the first column of the SVD represents, all I can say is that it is the
		component that explains most of the variance in the data - it captures the most information.
		<br><br>
		The technical details of SVD are beyond the scope of this explanation but for the interested, I recommend
		<a href="https://www.youtube.com/playlist?list=PLMrJAkhIeNNSVjnsviglFoY2nXildDCcv">Prof. Steve Brunton's YouTube Series</a> and his
		<a href="https://www.amazon.com/Data-Driven-Science-Engineering-Learning-Dynamical/dp/1108422098">Data-Driven Science and Engineering book</a>.
		<br><br>
		<button onclick="ShowDeets5()">See Your SVD</button>
		<br><br>
		<div id="Deets5">
		A <b>low-rank SVD</b> is one which captures the most-informative N components of an SVD projection. After testing low-rank SVD implementations
		<a href="https://github.com/BigBangData/NaturalLanguageProcessing/blob/fuji/SMS_SpamDetect/06_DimensionalityReduction.ipynb">here</a> and
		<a href="https://github.com/BigBangData/NaturalLanguageProcessing/blob/fuji/SMS_SpamDetect/06b_DimensionalityReduction.ipynb">here</a> I ended up
	 	adapting the <i>TruncatedSVD</i> class from Scikit-Learn's ML library
		(<a href="https://github.com/scikit-learn/scikit-learn/blob/95119c13af77c76e150b753485c662b7c52a41a2/sklearn/decomposition/_truncated_svd.py#L25">original</a>,
		<a href="https://github.com/BigBangData/SMS_SpamDetect/blob/aae96efb6e5ba9875efa3a2ede8d70958d8e025f/custom/deploy_models.py#L30">adaptation</a>) compressing
		the 2,000-long matrix into an 800-long one.
		<br><br>
		The reason I adapted the TruncatedSVD class is similar to the reason I kept the IDF values during the TF-IDF calculation. When we apply SVD to the original
		training matrix it is projected into a semantic space wherein SVD components represent higher-level semantic concepts in the training data, not in the new data.
	 	This training SVD space needs to be leveraged during the prediction process - we wouldn't be able to project a single document into this same
		latent semantic space without keeping matrices from the training data to be able to do so (see SVD deployment code below). Here are the first 17 SVD components
		of the 800-long vector, which proportionally correspond to about 42 terms in a 2,000-long vector yet capture a much greater
		 information signal:
		 <br><br>
		 <table class="table table-striped">
 			 <thead>
 					 <tr>
						 <th>Component</th>
 							<th>SVD Projection</th>
 					</tr>
 				</thead>
  			 <tbody>
 					{% for component in svd %}
					{% if loop.last %}
							<tr>
								<td>...</td>
								<td>...</td>
							</tr>
					{% else %}
 				  		<tr>
								<td>{{loop.index}}</td>
 								<td>{{component}}</td>
 							</tr>
					{% endif %}
 					{% endfor %}
 			 </tbody>
 		</table>
	</div>
	<br>
	<a href="https://github.com/BigBangData/NaturalLanguageProcessing/blob/fuji/SMS_SpamDetect/27_PreProcess_TestSet.ipynb">TruncatedSVD adaptation</a>,
	<a href="https://github.com/BigBangData/SMS_SpamDetect/blob/aae96efb6e5ba9875efa3a2ede8d70958d8e025f/custom/deploy_models.py#L108">SVD in deployment</a>
	</p>
	<p>
		<br>
		<h3>Computing Mean Spam Cosine Similarities</h3>
		<br>
		<button onclick="ShowDeets6()">See Detailed Explanation</button
		<br><br>
		<div id="Deets6">
			<br>
			Cosine similarity is the most common distance metric in natural language processing - it's been proven to be one of the most efficient ways to capture
			the similarity between documents. It is the cosine of the angle between documents represented as vectors in an
			<a href="https://en.wikipedia.org/wiki/Inner_product_space">inner product space.</a> Put simply, if we represent two documents as numeric vectors (as
			we did) we can compute how similar they are using the cosine of the angle between these documents in space. Since visualizing a multidimensional
			space isn't possible, we can build an intuition for this in a 2D Cartesian coordinate system where one axis represents a term and the other another term.
			We can plot documents with two terms as vectors in this plane. Say your corpus was "The Old Man and the Sea" and each document is a sentence in the book,
			yet we're only interested in the words "love" and "sea" since our space is only in 2D. The three vectors below represent three documents containing different
			counts of these words.
			<br><br>
			<center><img src="../static/img/Explanation5.PNG" alt="Explanation 5" width=33%></center>
			<center><i>Documents represented as vectors in a 2D plane</i></center>
			<br>
			The red vector to the left represents a document in which the word "love" happened twice but "sea" only once - this document has more love than sea
			so it angles toward the love axis. The black vector represents a document where "sea" happened six times and "love" twice - it has a lot more sea
			than love so it's closer to the sea axis despite having the same love count. The green vector in the middle is a middle ground between the two terms,
			thus the vector has a 45-degree angle. We can now compute the cosine of the angles between these vectors and compare how similar the documents are
			by how close they are to each other.
			<br><br>
			With other distance metrics (similarity is the opposite of distance, they're two sides of the same coin) such as the ubiquitous Euclidean distance
			("as the crow flies"), the magnitude (length, or word count) of a vector is very important (Euclidean distance squares it). Using Euclidean distance
			for computing document similarity would disproportionately weight how many times sea is mentioned in the black document and put it further away from
			the red document than it need be. By only considering the angle between two vectors the cosine similarity gives preference to the word mix, capturing
			more of the essence of a document.
		</div>
		<br>
		<li><b>How does this help a machine learning model distinguish spam from ham?</b></li>
		If we compute the mean cosine similarity between all documents in the training data (which has labels) and build a square
		matrix of cosine similarities between all documents, we can go through each row of this matrix and compute the mean cosine similarity for each
		document (spam or ham) of only the spam columns, creating a "mean spam cosine similarity" feature. The hypothesis is that ham messages will have
		low similarities compared to spam messages, in other words, spam is more similar to spam than ham. This not only stands to reason but it stands
		to visual scrutiny and further validation during model development. Below is the distribution of mean spam cosine similarities for ham and spam
		messages in the training data.
		<br><br>
		<center><img src="../static/img/Explanation6.PNG" alt="Explanation 6" width=50%></center>
		<center><i>Distribution of Ham v. Spam Mean Spam Cosine Similarities</i></center>
		<br>
		<button onclick="ShowDeets7()">See Your Mean Spam Cosine Similarity</button>
		<br><br>
		<div id="Deets7">
		Notice how small these values are - yet spam is clearly separable from ham. This is only one of the (now 801) features used to predict whether a
		text is ham or spam but it is probably the most powerful predictor. If your value is very close to zero or even negative, it is likely that the model
		will interpret it to be indicative of a legitimate message, but even a value of 0.005 is within the range of possible spam values for this feature:
		</thead>
		<br><br>
 	 	<table class="table table-striped">
 		 	<thead>
 				 <tr>
 					 <th>Mean Spam Cosine Similarity</th>
 				</tr>
 			</thead>
 			<tbody>
 				{% for sim in cossim %}
 						<tr>
 							<td>{{sim}}</td>
 						</tr>
 				{% endfor %}
 		 </tbody>
 		</table>
		</div>
	<br>
		<a href="https://github.com/BigBangData/NaturalLanguageProcessing/blob/fuji/SMS_SpamDetect/08_CosineSimilarity.ipynb">Cosine Similarity Notebook</a>,
		<a href="https://github.com/BigBangData/SMS_SpamDetect/blob/e0afac56b5b0569c431b2607ef24b83f7ed67390/custom/deploy_models.py#L113">Deployment Code</a>
	<br>
	</p>
	<p>
	<br>
	<h2 style="color:#3c90b5; text-align:center">Feeding The Processed Text Into A Model</h2>
	<br>
	The final processed numeric array is an 801-long vector that consists of the mean spam consine similarity feature stacked onto the 800-long SVD of the 2,000-long
	document-term matrix of TF-IDF scores. The entire processing step plus feeding this array into a pre-trained model and making a prediction is encapsulated by two
	lines of code in the final deployment script - two lines of code that accomplish a lot under the hood. We've covered the first line, now we'll cover the second.
	<br><br>
	<center><img src="../static/img/Explanation7.PNG" alt="Explanation 7" width=33%></center>
	<center><i>Preprocessing and predicting in
		<a href="https://github.com/BigBangData/SMS_SpamDetect/blob/d689cba5386ede7d06257632c28989ccba1115c9/spam-detect42.py#L37">
			two lines of code</a></i></center>
	<br>

	</p>
	<p>
	<br>
	<h2 style="color:#3c90b5; text-align:center">Making A Prediction</h2>
	<br>
	</p>
	<p>
	<br>
	<h2 style="color:#3c90b5; text-align:center">Rendering The Prediction</h2>
	<br>
	</p>
	<script>
	function ShowDeets1() {
	  var x = document.getElementById("Deets1");
	  if (x.style.display === "block") {
	    x.style.display = "none";
	  } else {
	    x.style.display = "block";
	  }
	}
	function ShowDeets2() {
		var y = document.getElementById("Deets2");
	  if (y.style.display === "block") {
	    y.style.display = "none";
	  } else {
	    y.style.display = "block";
	  }
	}
	function ShowDeets3() {
		var y = document.getElementById("Deets3");
	  if (y.style.display === "block") {
	    y.style.display = "none";
	  } else {
	    y.style.display = "block";
	  }
	}
	function ShowDeets4() {
		var y = document.getElementById("Deets4");
	  if (y.style.display === "block") {
	    y.style.display = "none";
	  } else {
	    y.style.display = "block";
	  }
	}
	function ShowDeets5() {
		var y = document.getElementById("Deets5");
	  if (y.style.display === "block") {
	    y.style.display = "none";
	  } else {
	    y.style.display = "block";
	  }
	}
	function ShowDeets6() {
		var y = document.getElementById("Deets6");
	  if (y.style.display === "block") {
	    y.style.display = "none";
	  } else {
	    y.style.display = "block";
	  }
	}
	function ShowDeets7() {
		var y = document.getElementById("Deets7");
	  if (y.style.display === "block") {
	    y.style.display = "none";
	  } else {
	    y.style.display = "block";
	  }
	}
	</script>
</body>
</html>
<footer>
	<div>
		<ul>
			<h3><a href="/">Try Again!</a></h3>
		</ul>
	</div>
</footer>
